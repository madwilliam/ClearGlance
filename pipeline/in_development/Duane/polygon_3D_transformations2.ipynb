{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_21614/678556094.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['x'] = data['x'].apply(lambda x: x / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['y'] = data['y'].apply(lambda y: y / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['z'] = data['z'].apply(lambda z: z / z_resolution_section_to_microns)\n",
      "/tmp/ipykernel_21614/678556094.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"unique_key\"] =  data[\"prep_id\"].astype(str) + '_' + data[\"label\"].astype(str) + '_' + data[\"z\"].round().astype(int).astype(str)\n",
      "/tmp/ipykernel_21614/678556094.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"coord\"] = list(zip(data['x'], data[\"y\"], data[\"z\"]))\n",
      "/tmp/ipykernel_21614/678556094.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['x'] = data['x'].apply(lambda x: x / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['y'] = data['y'].apply(lambda y: y / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['z'] = data['z'].apply(lambda z: z / z_resolution_section_to_microns)\n",
      "/tmp/ipykernel_21614/678556094.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"unique_key\"] =  data[\"prep_id\"].astype(str) + '_' + data[\"label\"].astype(str) + '_' + data[\"z\"].round().astype(int).astype(str)\n",
      "/tmp/ipykernel_21614/678556094.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"coord\"] = list(zip(data['x'], data[\"y\"], data[\"z\"]))\n",
      "/tmp/ipykernel_21614/678556094.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['x'] = data['x'].apply(lambda x: x / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['y'] = data['y'].apply(lambda y: y / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['z'] = data['z'].apply(lambda z: z / z_resolution_section_to_microns)\n",
      "/tmp/ipykernel_21614/678556094.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"unique_key\"] =  data[\"prep_id\"].astype(str) + '_' + data[\"label\"].astype(str) + '_' + data[\"z\"].round().astype(int).astype(str)\n",
      "/tmp/ipykernel_21614/678556094.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"coord\"] = list(zip(data['x'], data[\"y\"], data[\"z\"]))\n",
      "/tmp/ipykernel_21614/678556094.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['x'] = data['x'].apply(lambda x: x / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['y'] = data['y'].apply(lambda y: y / xy_resolution_microns_to_pixels)\n",
      "/tmp/ipykernel_21614/678556094.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['z'] = data['z'].apply(lambda z: z / z_resolution_section_to_microns)\n",
      "/tmp/ipykernel_21614/678556094.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"unique_key\"] =  data[\"prep_id\"].astype(str) + '_' + data[\"label\"].astype(str) + '_' + data[\"z\"].round().astype(int).astype(str)\n",
      "/tmp/ipykernel_21614/678556094.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"coord\"] = list(zip(data['x'], data[\"y\"], data[\"z\"]))\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openpyxl'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[0;32mIn [2]\u001B[0m, in \u001B[0;36m<cell line: 89>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     86\u001B[0m consolidated_coordinates[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvolume_ordering\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mfactorize(consolidated_coordinates[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvolume_id\u001B[39m\u001B[38;5;124m'\u001B[39m])[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m     88\u001B[0m \u001B[38;5;66;03m# SAVE DATA FOR YOAV INPUTS\u001B[39;00m\n\u001B[0;32m---> 89\u001B[0m \u001B[43mconsolidated_coordinates\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpolygons_volumes\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/pipeline38/lib/python3.8/site-packages/pandas/core/generic.py:2345\u001B[0m, in \u001B[0;36mNDFrame.to_excel\u001B[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes, storage_options)\u001B[0m\n\u001B[1;32m   2332\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mformats\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexcel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExcelFormatter\n\u001B[1;32m   2334\u001B[0m formatter \u001B[38;5;241m=\u001B[39m ExcelFormatter(\n\u001B[1;32m   2335\u001B[0m     df,\n\u001B[1;32m   2336\u001B[0m     na_rep\u001B[38;5;241m=\u001B[39mna_rep,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2343\u001B[0m     inf_rep\u001B[38;5;241m=\u001B[39minf_rep,\n\u001B[1;32m   2344\u001B[0m )\n\u001B[0;32m-> 2345\u001B[0m \u001B[43mformatter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2346\u001B[0m \u001B[43m    \u001B[49m\u001B[43mexcel_writer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2347\u001B[0m \u001B[43m    \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstartrow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstartrow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstartcol\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstartcol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfreeze_panes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfreeze_panes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2352\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2353\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/pipeline38/lib/python3.8/site-packages/pandas/io/formats/excel.py:888\u001B[0m, in \u001B[0;36mExcelFormatter.write\u001B[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options)\u001B[0m\n\u001B[1;32m    884\u001B[0m     need_save \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    885\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    886\u001B[0m     \u001B[38;5;66;03m# error: Cannot instantiate abstract class 'ExcelWriter' with abstract\u001B[39;00m\n\u001B[1;32m    887\u001B[0m     \u001B[38;5;66;03m# attributes 'engine', 'save', 'supported_extensions' and 'write_cells'\u001B[39;00m\n\u001B[0;32m--> 888\u001B[0m     writer \u001B[38;5;241m=\u001B[39m \u001B[43mExcelWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[abstract]\u001B[39;49;00m\n\u001B[1;32m    889\u001B[0m \u001B[43m        \u001B[49m\u001B[43mwriter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstorage_options\u001B[49m\n\u001B[1;32m    890\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    891\u001B[0m     need_save \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    893\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/pipeline38/lib/python3.8/site-packages/pandas/io/excel/_openpyxl.py:49\u001B[0m, in \u001B[0;36mOpenpyxlWriter.__init__\u001B[0;34m(self, path, engine, date_format, datetime_format, mode, storage_options, if_sheet_exists, engine_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     37\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m     38\u001B[0m     path,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     47\u001B[0m ):\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;66;03m# Use the openpyxl module as the Excel writer.\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mopenpyxl\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mworkbook\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Workbook\n\u001B[1;32m     51\u001B[0m     engine_kwargs \u001B[38;5;241m=\u001B[39m combine_kwargs(engine_kwargs, kwargs)\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m     54\u001B[0m         path,\n\u001B[1;32m     55\u001B[0m         mode\u001B[38;5;241m=\u001B[39mmode,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     58\u001B[0m         engine_kwargs\u001B[38;5;241m=\u001B[39mengine_kwargs,\n\u001B[1;32m     59\u001B[0m     )\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'openpyxl'"
     ]
    }
   ],
   "source": [
    "# CREATED: 4-APR-2022\n",
    "# LAST EDIT: 10-MAY-2022\n",
    "# AUTHOR(S): DUANE RINEHART\n",
    "'''\n",
    "IMPORT POLYGON POINTS FROM CSV (EVENTUALLY PULL FROM RDBMS)\n",
    "Note: polygons_dump5.csv GENERATED WITH QUERY - SELECT * FROM annotations_points WHERE (prep_id='DK55' AND (label='7N_L' OR label='5N_L')) OR (prep_id='MD594' AND (label='SC' OR label='IC'))\n",
    "'''\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "win_data_dir = 'E:/dev/'\n",
    "linux_data_dir = '/mnt/e/dev/'\n",
    "\n",
    "\n",
    "'''\n",
    "SET SRC FOLDER BASED (CROSS-PLATFORM)\n",
    "'''\n",
    "if os.name == \"nt\":\n",
    "    input_fullPath = os.path.join(win_data_dir)\n",
    "else:\n",
    "    input_fullPath = os.path.join(linux_data_dir)\n",
    "\n",
    "infile = os.path.join(input_fullPath, \"MD585_dump5.csv\")\n",
    "outfile = os.path.join(input_fullPath, \"output_for_Yoav_testdel.xlsx\")\n",
    "\n",
    "def load_raw_data(infile):\n",
    "    return pd.read_csv(infile, sep='\\t', index_col=0)\n",
    "\n",
    "\n",
    "def parse_df(df_raw_data, prep_id, label, xy_resolution_microns_to_pixels, z_resolution_section_to_microns):\n",
    "    data = df_raw_data[np.logical_and(df_raw_data.prep_id==prep_id,df_raw_data.label==label)]\n",
    "    data['x'] = data['x'].apply(lambda x: x / xy_resolution_microns_to_pixels)\n",
    "    data['y'] = data['y'].apply(lambda y: y / xy_resolution_microns_to_pixels)\n",
    "    data['z'] = data['z'].apply(lambda z: z / z_resolution_section_to_microns)\n",
    "    data[\"unique_key\"] =  data[\"prep_id\"].astype(str) + '_' + data[\"label\"].astype(str) + '_' + data[\"z\"].round().astype(int).astype(str)\n",
    "    data[\"coord\"] = list(zip(data['x'], data[\"y\"], data[\"z\"]))\n",
    "    data[(data['prep_id'] == prep_id) & (data['label'] == label)]\n",
    "    data = data.rename(columns={'ordering': 'polygon_ordering'})\n",
    "\n",
    "    #RECODE, IF NECESSARY\n",
    "    data.loc[data[\"FK_structure_id\"] == 54, \"FK_structure_id\"] = \"POLYGON\"\n",
    "    data.loc[data[\"FK_owner_id\"] == 4, \"FK_owner_id\"] = \"dk\"\n",
    "    data.loc[data[\"FK_owner_id\"] == 37, \"FK_owner_id\"] = \"beth\"\n",
    "    data.loc[data[\"FK_input_id\"] == 1, \"FK_input_id\"] = \"manual person\"\n",
    "\n",
    "\n",
    "    selected_columns = data[\n",
    "        [\"unique_key\", \"prep_id\", \"label\", \"coord\", \"z\", \"polygon_id\", \"volume_id\", \"polygon_ordering\"]\n",
    "    ]  # EXTRACT SPECIFIC COLUMNS FOR ANALYSIS\n",
    "\n",
    "    # selected_columns = data[\n",
    "    #     [\"unique_key\", \"prep_id\", \"label\", \"coord\", \"z\", \"polygon_ordering\", 'volume_ordering']\n",
    "    # ]  # EXTRACT SPECIFIC COLUMNS FOR ANALYSIS\n",
    "\n",
    "    return selected_columns\n",
    "\n",
    "\n",
    "df_raw_data = load_raw_data(infile) # REPLACE W/ RDBMS CALL FOR PRODUCTION\n",
    "\n",
    "\n",
    "# FILTERING CONSTANTS\n",
    "z_resolution_section_to_microns = 20 # STORED IN DB\n",
    "\n",
    "# POLYGON SETS BY prep_id, label CREATED INDIVIDUALLY BELOW FOR TESTING\n",
    "prep_id = 'MD594'\n",
    "xy_resolution_microns_to_pixels = .452 # STORED IN DB (FOR FOUNDATION BRAINS)\n",
    "label = 'SC'\n",
    "extracted_columns_MD594_SC = parse_df(df_raw_data, prep_id, label, xy_resolution_microns_to_pixels, z_resolution_section_to_microns)\n",
    "label = 'IC'\n",
    "extracted_columns_MD594_IC = parse_df(df_raw_data, prep_id, label, xy_resolution_microns_to_pixels, z_resolution_section_to_microns)\n",
    "prep_id = 'DK55'\n",
    "xy_resolution_pixels_microns = .325 # STORED IN DB (FOR DK55)\n",
    "label = '7N_L'\n",
    "extracted_columns_DK55_7N_L = parse_df(df_raw_data, prep_id, label, xy_resolution_microns_to_pixels, z_resolution_section_to_microns)\n",
    "label = '7N_R'\n",
    "extracted_columns_DK55_7N_R = parse_df(df_raw_data, prep_id, label, xy_resolution_microns_to_pixels, z_resolution_section_to_microns)\n",
    "\n",
    "# EACH DATAFRAME CONTAINS LIST OF TUPLES (coord) THAT MAY BE USED FOR PLOTTING POLYGONS IN NEUROGLANCER (SOME EXAMPLES IN NOTEBOOK - BELOW)\n",
    "\n",
    "# FOLLOWING CODE ONLY USEFUL IF BATCH PROCESSING ALL DATA (HOWEVER FOR INTEGRATION IN APP (PIPELINE), LIKELY DB QUERY WITH LOOP IS SUFFICIENT)\n",
    "\n",
    "consolidated_coordinates = pd.concat([extracted_columns_MD594_SC, extracted_columns_MD594_IC, extracted_columns_DK55_7N_L, extracted_columns_DK55_7N_R])\n",
    "\n",
    "#ENCODE VOLUME ID AS CATEGORICAL VARIABLE\n",
    "consolidated_coordinates['volume_ordering'] = pd.factorize(consolidated_coordinates['volume_id'])[0]\n",
    "\n",
    "# SAVE DATA FOR YOAV INPUTS\n",
    "consolidated_coordinates.to_excel(outfile, sheet_name='polygons_volumes')\n",
    "\n",
    "# # CREATE DICTIONARY OF COORDINATES\n",
    "# transformed_polygon_structures = consolidated_coordinates.groupby(['unique_key'])['coord'].apply(lambda x: list(np.unique(x))).to_dict()\n",
    "#\n",
    "# # OUTPUT FORMAT:\n",
    "# # -KEY IS CONCATENATED prep_id_structure_section (\"_\" delimiter)\n",
    "# # -VALUE IS LIST OF COORDINATE TUPLES (x, y, z)\n",
    "# #\n",
    "# # TO ACCESS [EXAMPLE WITH prep_id 'MD594', label 'IC', section 140]:\n",
    "# polygon_index = 'MD594_IC_140'\n",
    "# for coordinate_list in transformed_polygon_structures[polygon_index]:\n",
    "#     print(coordinate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "data": {
      "text/plain": "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n       221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n       234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n       247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259,\n       260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272,\n       273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285,\n       286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298,\n       299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n       312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324,\n       325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337,\n       338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350,\n       351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n       364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376,\n       377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389,\n       390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402,\n       403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415,\n       416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428],\n      dtype=int64)"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "consolidated_coordinates['volume_ordering'] = pd.factorize(consolidated_coordinates['polygon_id'])[0]\n",
    "consolidated_coordinates['volume_ordering'].unique()\n",
    "#data = df_raw_data[np.logical_and(df_raw_data.prep_id==prep_id,df_raw_data.label==label)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "outputs": [
    {
     "data": {
      "text/plain": "array([161., 157., 248., 173., 164., 279., 209., 268., 274., 200., 263.,\n       176., 146., 288., 296., 189., 196., 165., 212., 186., 160., 214.,\n       217., 178., 287., 292., 202., 139., 218., 199., 163., 219., 242.,\n       260., 142., 272., 188., 179., 175., 144., 152., 137., 205., 167.,\n       251., 203., 235., 305., 285., 184., 195., 228., 266., 236., 239.,\n       270., 282., 267., 241., 148., 306., 162., 197., 244., 291., 169.,\n       293., 194., 280., 229., 230., 149., 143., 256., 177., 147., 180.,\n       245., 150., 172., 231., 204., 304., 246., 275., 171., 249., 181.,\n       207., 286., 201., 257., 281., 237., 259., 182., 262., 278., 250.,\n       254., 158., 215., 232., 252., 225., 301., 307., 276., 233., 154.,\n       289., 166., 309., 210., 269., 192., 255., 265., 308., 299., 220.,\n       298., 243., 226., 138., 170., 159., 271., 213., 211., 284., 300.,\n       221., 290., 198., 141., 185., 206., 190., 223., 151., 247., 153.,\n       155., 297., 253., 208., 140., 227., 183., 222., 234., 168., 156.,\n       216., 295., 273., 277., 224., 264., 258., 145., 294., 191., 303.,\n       302., 283., 174., 240.])"
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO VIEW RANGE OF SECTION VALUES FOR BRAIN/STRUCTURE (STORED SEPARATELY)\n",
    "extracted_columns_MD594_SC.z.unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "data": {
      "text/plain": "id\n242321    9a661f4f149f6571e0873cf2182d12f5a54a2452\n242322    9a661f4f149f6571e0873cf2182d12f5a54a2452\n242323    9a661f4f149f6571e0873cf2182d12f5a54a2452\n242324    9a661f4f149f6571e0873cf2182d12f5a54a2452\n242325    9a661f4f149f6571e0873cf2182d12f5a54a2452\n                            ...                   \n264258    9a661f4f149f6571e0873cf2182d12f5a54a2452\n264259    9a661f4f149f6571e0873cf2182d12f5a54a2452\n264260    9a661f4f149f6571e0873cf2182d12f5a54a2452\n264261    9a661f4f149f6571e0873cf2182d12f5a54a2452\n264262    9a661f4f149f6571e0873cf2182d12f5a54a2452\nName: volume_id, Length: 21942, dtype: object"
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TO VIEW VOLUME IDS FOR SPECIFIC STRUCTURE (EACH PREP_ID AND BRAIN STRUCTURE STORED SEPARATELY)\n",
    "extracted_columns_MD594_SC.volume_id"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 1, 2, 3])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "consolidated_coordinates['volume_ordering'].unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT FOLDER: /net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK59/preps/CH1/full_aligned\n",
      "CURRENT FILE COUNT: 388\n",
      "OUTPUT FOLDER: /net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK59/neuroglancer_data/test\n",
      "FILE READ: /net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK59/preps/CH1/full_aligned/000.tif\n",
      "VOLUME DIMENSIONS: (68157, 31465, 1)\n",
      "TRYING TO ADD (<class 'numpy.ndarray'>, (68157, 31465, 1)) TO INDEX: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upload: 100%|█████████▉| 8293/8308 [00:44<00:00, 229.69it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from cloudvolume import CloudVolume\n",
    "from skimage import measure, io\n",
    "\n",
    "prep_id = 'DK59'\n",
    "channel = 1\n",
    "INPUT = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{prep_id}/preps/CH1/thumbnail_aligned'\n",
    "OUTPUT_DIR = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{prep_id}/neuroglancer_data/test'\n",
    "FINAL_OUTPUT_DIR = os.path.join(OUTPUT_DIR, f\"C{channel}T\")\n",
    "\n",
    "\n",
    "def sizeof_fmt(num, suffix=\"B\"):\n",
    "    for unit in [\"\", \"Ki\", \"Mi\", \"Gi\", \"Ti\", \"Pi\", \"Ei\", \"Zi\"]:\n",
    "        if abs(num) < 1024.0:\n",
    "            return f\"{num:3.1f}{unit}{suffix}\"\n",
    "        num /= 1024.0\n",
    "    return f\"{num:.1f}Yi{suffix}\"\n",
    "\n",
    "    \n",
    "os.makedirs(FINAL_OUTPUT_DIR, exist_ok=True)\n",
    "infiles = os.listdir(INPUT)\n",
    "\n",
    "print(f\"INPUT FOLDER: {INPUT}\")\n",
    "print(f\"CURRENT FILE COUNT: {len(infiles)}\")\n",
    "print(f\"OUTPUT FOLDER: {OUTPUT_DIR}\")\n",
    "\n",
    "resolution_scales = [325, 325, 20000]\n",
    "chunk_size = [512, 512, 16] # units are voxels [recommended powers of 2; 2**9=512]\n",
    "\n",
    "\n",
    "\n",
    "#for infile in infiles:\n",
    "infile = os.path.join(INPUT, '000.tif') \n",
    "index = int(os.path.splitext(os.path.basename(infile))[0])\n",
    "\n",
    "try:\n",
    "    img = io.imread(infile, img_num=0)\n",
    "    print(f\"FILE READ: {infile}\")\n",
    "    # print(f\"RAW SIZE: {sizeof_fmt(rbytes)}\")\n",
    "    # sparse_img = sparse.COO(img)\n",
    "    # sparse_bytes = sparse_img.nbytes\n",
    "    # print(f\"SPARSE SIZE: {sizeof_fmt(sparse_bytes)}\")\n",
    "except IOError as ioe:\n",
    "    print(f'could not open {infile} {ioe}')\n",
    "try:\n",
    "    img = img.reshape(channel, img.shape[0], img.shape[1]).T\n",
    "    volume_and_image_size = img.shape\n",
    "    #volume_and_image_size = (img.shape[0], img.shape[1], len(infiles))\n",
    "    print(f\"VOLUME DIMENSIONS: {volume_and_image_size}\")\n",
    "except:\n",
    "    print(f'could not reshape {infile}')\n",
    "\n",
    "info = CloudVolume.create_new_info(\n",
    "    num_channels    = 1,\n",
    "    layer_type      = 'image',\n",
    "    data_type       = 'uint16', # Channel images might be 'uint8'\n",
    "    # raw, png, jpeg, compressed_segmentation, fpzip, kempressed, compresso\n",
    "    encoding        = 'raw', \n",
    "    resolution      = resolution_scales, # Voxel scaling, units are in nanometers\n",
    "    voxel_offset    = [0, 0, 0], # x,y,z offset in voxels from the origin\n",
    "    # Pick a convenient size for your underlying chunk representation\n",
    "    # Powers of two are recommended, doesn't need to cover image exactly\n",
    "    chunk_size      = chunk_size, # units are voxels\n",
    "    volume_size     = volume_and_image_size, # e.g. a cubic millimeter dataset\n",
    ")\n",
    "precomputed_vol = CloudVolume(f'file://{FINAL_OUTPUT_DIR}', mip=0, info=info, delete_black_uploads=True, compress=True, progress=True, parallel=True)\n",
    "precomputed_vol.commit_info()\n",
    "precomputed_vol.parallel = 15\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    print(f\"TRYING TO ADD {type(img), img.shape} TO INDEX: {index}\")\n",
    "    precomputed_vol[:, :, index] = img\n",
    "        # if orientation == 'sagittal':\n",
    "        #     self.precomputed_vol[:, :, index] = img\n",
    "        # elif orientation == 'coronal':\n",
    "        #     self.precomputed_vol[index, :, :] = img \n",
    "        # elif orientation == 'horizontal':\n",
    "        #     self.precomputed_vol[:, index, :] = img\n",
    "except:\n",
    "    print(f'could not set {infile} to precomputed')\n",
    "\n",
    "precomputed_vol.commit_provenance()\n",
    "precomputed_vol.cache.flush()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_494071/2009422848.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mdel\u001B[0m \u001B[0mimg\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mimg\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;31m#print(sparse_img.shape)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;31m#sparse_img.reshape(channel, sparse_img.shape[0], sparse_img.shape[1]).T\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m#print(sparse_img.shape)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'img' is not defined"
     ]
    }
   ],
   "source": [
    "del img\n",
    "print(img.shape)\n",
    "#print(sparse_img.shape)\n",
    "#sparse_img.reshape(channel, sparse_img.shape[0], sparse_img.shape[1]).T\n",
    "#print(sparse_img.shape)\n",
    "#volume_and_image_size\n",
    "#precomputed_vol[:, :, index] = img\n",
    "\n",
    "#sparse_img.reshape(channel, img.shape[0], img.shape[1]).T\n",
    "#print(index,type(index))\n",
    "#infile = os.path.join(INPUT, '000.tif') #virtually empty file\n",
    "#index = os.path.splitext(infile)[0]\n",
    "\n",
    "#precomputed_vol[:, :, index] = img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('pipeline')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9b29855540defb355a50951874e4b3a9a33e036ed29af88ad65ef37e45f70f6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
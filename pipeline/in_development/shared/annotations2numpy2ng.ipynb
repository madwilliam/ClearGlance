{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ast\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import neuroglancer\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "import imagesize\n",
    "\n",
    "HOME = os.path.expanduser(\"~\")\n",
    "PATH = os.path.join(HOME, 'programming/pipeline_utility/src')\n",
    "sys.path.append(PATH)\n",
    "from Controllers.SqlController import SqlController\n",
    "from lib.FileLocationManager import DATA_PATH, FileLocationManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "animal = 'MD585'\n",
    "downsample_factor = 32\n",
    "# OUTPUT_DIR_PATH = os.path.join(os.path.expanduser('~'))\n",
    "OUTPUT_DIR_PATH = os.path.join('./')\n",
    "CSV_DIR_PATH = '/net/birdstore/Active_Atlas_Data/data_root/atlas_data/foundation_brain_annotations'\n",
    "INPUT = f'/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/{animal}/preps/CH1/thumbnail'\n",
    "sqlController = SqlController(animal)\n",
    "resolution = sqlController.scan_run.resolution\n",
    "aligned_shape = np.array((sqlController.scan_run.width, sqlController.scan_run.height))\n",
    "num_section = len(os.listdir(INPUT))\n",
    "downsampled_aligned_shape = np.round(aligned_shape / downsample_factor).astype(int)\n",
    "scales = np.array([resolution * downsample_factor, resolution * downsample_factor, 20]) * 1000\n",
    "structures = sqlController.get_structures_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SC': ['Superior colliculus', 18]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the annotation points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_coordinates(coor_list):\n",
    "    dense_coor_list = []\n",
    "    # Shortest distance, x, y\n",
    "\n",
    "    # for x, y in coor_list:\n",
    "    for i in range(len(coor_list) - 1):\n",
    "        x, y = coor_list[i]\n",
    "        x_next, y_next = coor_list[i + 1]\n",
    "\n",
    "        x_mid = (x + x_next) / 2\n",
    "        y_mid = (y + y_next) / 2\n",
    "\n",
    "        dense_coor_list.append([x, y])\n",
    "        dense_coor_list.append([x_mid, y_mid])\n",
    "\n",
    "        if i == len(coor_list) - 2:\n",
    "            dense_coor_list.append([x_next, y_next])\n",
    "            x, y = coor_list[0]\n",
    "            x_mid = (x + x_next) / 2\n",
    "            y_mid = (y + y_next) / 2\n",
    "            dense_coor_list.append([x_mid, y_mid])\n",
    "\n",
    "    return dense_coor_list\n",
    "\n",
    "def get_contours_from_annotations(stack, target_structure, hand_annotations, densify=0):\n",
    "    MD585_ng_section_min = 83\n",
    "    num_annotations = len(hand_annotations)\n",
    "    str_contours_annotation = {}\n",
    "\n",
    "    for i in range(num_annotations):\n",
    "        structure = hand_annotations['name'][i]\n",
    "        side = hand_annotations['side'][i]\n",
    "        section = hand_annotations['section'][i]\n",
    "        first_sec = 0\n",
    "        last_sec = 0\n",
    "\n",
    "        #if side == 'R' or side == 'L':\n",
    "        #    structure = structure + '_' + side\n",
    "\n",
    "        if structure == target_structure:\n",
    "            vertices = hand_annotations['vertices'][i]\n",
    "\n",
    "            for i in range(densify):\n",
    "                vertices = get_dense_coordinates(vertices)\n",
    "\n",
    "            # Skip sections before the 22nd prep2 section for MD585 as there are clear errors\n",
    "            if stack == 'MD585' and section < MD585_ng_section_min + 22:\n",
    "                # vertices = vertices - np.array(MD585_abberation_correction)\n",
    "                continue\n",
    "            str_contours_annotation[section] = {}\n",
    "            str_contours_annotation[section][structure] = {}\n",
    "            str_contours_annotation[section][structure][1] = vertices\n",
    "\n",
    "    try:\n",
    "        first_sec = np.min(list(str_contours_annotation.keys()))\n",
    "        last_sec = np.max(list(str_contours_annotation.keys()))\n",
    "    except:\n",
    "        pass\n",
    "    return str_contours_annotation, first_sec, last_sec\n",
    "\n",
    "csvfile = os.path.join(CSV_DIR_PATH, f'{animal}_annotation.csv')\n",
    "hand_annotations = pd.read_csv(csvfile)\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'] \\\n",
    "    .apply(lambda x: x.replace(' ', ','))\\\n",
    "    .apply(lambda x: x.replace('\\n',','))\\\n",
    "    .apply(lambda x: x.replace(',]',']'))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ','))\\\n",
    "    .apply(lambda x: x.replace(',,', ',')).apply(lambda x: x.replace(',,', ','))\n",
    "hand_annotations['vertices'] = hand_annotations['vertices'].apply(lambda x: ast.literal_eval(x))\n",
    "section_structure_vertices = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 26.44it/s]\n"
     ]
    }
   ],
   "source": [
    "for structure, values in tqdm(structures.items()):\n",
    "    contour_annotations, first_sec, last_sec = get_contours_from_annotations(animal, structure, hand_annotations, densify=0)\n",
    "    for section in contour_annotations:\n",
    "        section_structure_vertices[section][structure] = contour_annotations[section][structure][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_clean transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446/446 [00:00<00:00, 15999.89it/s]\n"
     ]
    }
   ],
   "source": [
    "section_offset = {}\n",
    "for file in tqdm(sorted(os.listdir(INPUT))):\n",
    "    filepath = os.path.join(INPUT, file)\n",
    "    width, height = imagesize.get(filepath)\n",
    "    downsampled_shape = np.array((width, height))    \n",
    "    section = int(file.split('.')[0])\n",
    "    section_offset[section] = (downsampled_aligned_shape - downsampled_shape) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([51., 61.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_offset[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce create_alignment transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_elastix_parameter_file(filepath, tf_type=None):\n",
    "    \"\"\"\n",
    "    Parse elastix parameter result file.\n",
    "    \"\"\"\n",
    "    def parameter_elastix_parameter_file_to_dict(filename):\n",
    "        d = {}\n",
    "        with open(filename, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "                if line.startswith('('):\n",
    "                    tokens = line[1:-2].split(' ')\n",
    "                    key = tokens[0]\n",
    "                    if len(tokens) > 2:\n",
    "                        value = []\n",
    "                        for v in tokens[1:]:\n",
    "                            try:\n",
    "                                value.append(float(v))\n",
    "                            except ValueError:\n",
    "                                value.append(v)\n",
    "                    else:\n",
    "                        v = tokens[1]\n",
    "                        try:\n",
    "                            value = (float(v))\n",
    "                        except ValueError:\n",
    "                            value = v\n",
    "                    d[key] = value\n",
    "            return d\n",
    "\n",
    "    d = parameter_elastix_parameter_file_to_dict(filepath)\n",
    "\n",
    "    if tf_type is None:\n",
    "        # For alignment composition script\n",
    "        rot_rad, x_mm, y_mm = d['TransformParameters']\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        # center[1] = d['Size'][1] - center[1]\n",
    "\n",
    "        xshift = x_mm / d['Spacing'][0]\n",
    "        yshift = y_mm / d['Spacing'][1]\n",
    "\n",
    "        R = np.array([[np.cos(rot_rad), -np.sin(rot_rad)],\n",
    "                      [np.sin(rot_rad), np.cos(rot_rad)]])\n",
    "        shift = center + (xshift, yshift) - np.dot(R, center)\n",
    "        T = np.vstack([np.column_stack([R, shift]), [0, 0, 1]])\n",
    "        return T\n",
    "\n",
    "    elif tf_type == 'rigid3d':\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        shift = p[3:] / np.array(d['Spacing'])\n",
    "\n",
    "        thetax, thetay, thetaz = p[:3]\n",
    "        # Important to use the negative angle.\n",
    "        cx = np.cos(-thetax)\n",
    "        cy = np.cos(-thetay)\n",
    "        cz = np.cos(-thetaz)\n",
    "        sx = np.sin(-thetax)\n",
    "        sy = np.sin(-thetay)\n",
    "        sz = np.sin(-thetaz)\n",
    "        Rx = np.array([[1, 0, 0], [0, cx, sx], [0, -sx, cx]])\n",
    "        Ry = np.array([[cy, 0, sy], [0, 1, 0], [-sy, 0, cy]])\n",
    "        Rz = np.array([[cz, sz, 0], [-sz, cz, 0], [0, 0, 1]])\n",
    "\n",
    "        R = np.dot(np.dot(Rz, Ry), Rx)\n",
    "        # R = np.dot(np.dot(Rx, Ry), Rz)\n",
    "        # The order could be Rx,Ry,Rz - not sure.\n",
    "\n",
    "        return R, shift, center\n",
    "\n",
    "    elif tf_type == 'affine3d':\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        L = p[:9].reshape((3, 3))\n",
    "        shift = p[9:] / np.array(d['Spacing'])\n",
    "        center = np.array(d['CenterOfRotationPoint']) / np.array(d['Spacing'])\n",
    "        # shift = center + shift - np.dot(L, center)\n",
    "        # T = np.column_stack([L, shift])\n",
    "        return L, shift, center\n",
    "\n",
    "    elif tf_type == 'bspline3d':\n",
    "        n_params = d['NumberOfParameters']\n",
    "        p = np.array(d['TransformParameters'])\n",
    "        grid_size = d['GridSize']\n",
    "        grid_spacing = d['GridSpacing']\n",
    "        grid_origin = d['GridOrigin']\n",
    "\n",
    "        return L, shift, center\n",
    "\n",
    "def load_consecutive_section_transform(stack, moving_fn, fixed_fn):\n",
    "    \"\"\"\n",
    "    Load pairwise transform.\n",
    "\n",
    "    Returns:\n",
    "        (3,3)-array.\n",
    "    \"\"\"\n",
    "    assert stack is not None\n",
    "    fileLocationManager = FileLocationManager(stack)\n",
    "    elastix_output_dir = fileLocationManager.elastix_dir\n",
    "    param_fp = os.path.join(elastix_output_dir, moving_fn + '_to_' + fixed_fn, 'TransformParameters.0.txt')\n",
    "    #sys.stderr.write('Load elastix-computed transform: %s\\n' % param_fp)\n",
    "    if not os.path.exists(param_fp):\n",
    "        raise Exception('Transform file does not exist: %s to %s, %s' % (moving_fn, fixed_fn, param_fp))\n",
    "    transformation_to_previous_sec = parse_elastix_parameter_file(param_fp)\n",
    "\n",
    "    return transformation_to_previous_sec\n",
    "\n",
    "def parse_elastix(animal):\n",
    "    \"\"\"\n",
    "    After the elastix job is done, this goes into each subdirectory and parses the Transformation.0.txt file\n",
    "    Args:\n",
    "        animal: the animal\n",
    "    Returns: a dictionary of key=filename, value = coordinates\n",
    "    \"\"\"\n",
    "    fileLocationManager = FileLocationManager(animal)\n",
    "    DIR = fileLocationManager.prep\n",
    "    INPUT = os.path.join(DIR, 'CH1', 'thumbnail_cleaned')\n",
    "\n",
    "    image_name_list = sorted(os.listdir(INPUT))\n",
    "    anchor_idx = len(image_name_list) // 2\n",
    "    # anchor_idx = len(image_name_list) - 1\n",
    "    transformation_to_previous_sec = {}\n",
    "\n",
    "    for i in range(1, len(image_name_list)):\n",
    "        fixed_fn = os.path.splitext(image_name_list[i - 1])[0]\n",
    "        moving_fn = os.path.splitext(image_name_list[i])[0]\n",
    "        transformation_to_previous_sec[i] = load_consecutive_section_transform(animal, moving_fn, fixed_fn)\n",
    "\n",
    "    transformation_to_anchor_sec = {}\n",
    "    # Converts every transformation\n",
    "    for moving_idx in range(len(image_name_list)):\n",
    "        if moving_idx == anchor_idx:\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = np.eye(3)\n",
    "        elif moving_idx < anchor_idx:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx, moving_idx, -1):\n",
    "                T_composed = np.dot(np.linalg.inv(transformation_to_previous_sec[i]), T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "        else:\n",
    "            T_composed = np.eye(3)\n",
    "            for i in range(anchor_idx + 1, moving_idx + 1):\n",
    "                T_composed = np.dot(transformation_to_previous_sec[i], T_composed)\n",
    "            transformation_to_anchor_sec[image_name_list[moving_idx]] = T_composed\n",
    "\n",
    "    return transformation_to_anchor_sec\n",
    "\n",
    "def create_warp_transforms(transforms, downsample_factor=32):\n",
    "    def convert_2d_transform_forms(arr):\n",
    "        return np.vstack([arr, [0, 0, 1]])\n",
    "    \n",
    "    transforms_scale_factor = 32 / downsample_factor \n",
    "    tf_mat_mult_factor = np.array([[1, 1, transforms_scale_factor], [1, 1, transforms_scale_factor]])\n",
    "    transforms_to_anchor = {}\n",
    "    for img_name, tf in transforms.items():\n",
    "        transforms_to_anchor[img_name] = convert_2d_transform_forms(np.reshape(tf, (3, 3))[:2] * tf_mat_mult_factor) \n",
    "\n",
    "    return transforms_to_anchor\n",
    "\n",
    "transforms = parse_elastix(animal)\n",
    "warp_transforms = create_warp_transforms(transforms, downsample_factor)\n",
    "ordered_transforms = sorted(warp_transforms.items())\n",
    "\n",
    "section_transform = {}\n",
    "for section, transform in ordered_transforms:\n",
    "    section_num = int(section.split('.')[0])\n",
    "    transform = np.linalg.inv(transform)\n",
    "    section_transform[section_num] = transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99027576e-01,  4.40897031e-02, -1.04921179e+02],\n",
       "       [-4.40897031e-02,  9.99027576e-01,  3.22309683e+01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms['240.tif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99027576e-01, -4.40897031e-02,  1.06240205e+02],\n",
       "       [ 4.40897031e-02,  9.99027576e-01, -2.75736825e+01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "section_transform[240]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alignment of annotation coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_create_alignment(points, transform):\n",
    "    '''\n",
    "    (x, y) = points[i]\n",
    "    T = transform\n",
    "    \n",
    "    (x', y') = (x * sx + y * ry + tx, x * rx + y * sy + ty)\n",
    "    'sx': T[0, 0], 'sy': T[1, 1], 'rx': T[1, 0], 'ry': T[0, 1], 'tx': T[0, 2], 'ty': T[1, 2]\n",
    "    '''\n",
    "    a = np.hstack((points, np.ones((points.shape[0], 1))))\n",
    "    b = transform.T[:, 0:2]\n",
    "    c = np.matmul(a, b)\n",
    "    return c\n",
    "\n",
    "aligned_section_structure_polygons = defaultdict(dict)\n",
    "for section in section_structure_vertices:\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure]) / downsample_factor\n",
    "        #points = np.array(section_structure_vertices[section][structure]) \n",
    "        points = points + section_offset[section] # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "        aligned_section_structure_polygons[section][structure] = [points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_structures = defaultdict(dict)\n",
    "for section in section_structure_vertices:\n",
    "    for structure in section_structure_vertices[section]:\n",
    "        points = np.array(section_structure_vertices[section][structure])  / downsample_factor\n",
    "        points = points + section_offset[section] # create_clean offset\n",
    "        points = transform_create_alignment(points, section_transform[section]) # create_alignment transform\n",
    "        aligned_structures[structure][section] = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aligned structures SC At 136 (29, 2) [707.20741699 260.81367919] [698.12488614 251.73713315] [717.20978746 270.69814379]\n"
     ]
    }
   ],
   "source": [
    "points = aligned_structures['SC'][136]\n",
    "print('aligned structures SC At 136', points.shape,np.mean(points, axis=0), np.min(points, axis=0), np.max(points, axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sort(sub_li):\n",
    "  \n",
    "    # reverse = None (Sorts in Ascending order)\n",
    "    # key is set to sort using second element of \n",
    "    # sublist lambda has been used\n",
    "    return(sorted(sub_li, key = lambda x: x[1]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure, struct_dict in aligned_structures.items():\n",
    "    for section, points in struct_dict.items():\n",
    "        if section < 137:\n",
    "            print(structure, section, np.min(points, axis=0),np.max(points, axis=0) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "vertices_path = os.path.join(OUTPUT_DIR_PATH, f'{animal}_aligned_section_structure_polygons_down{downsample_factor}.pickle')\n",
    "with open(vertices_path, 'wb') as file:\n",
    "    pickle.dump(aligned_section_structure_polygons, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point, aligned_section_structure_polygons variable contains the aligned polygon vertices for each structure in each section. \n",
    "From now on, we introduce how to draw these points to numpy array or neuroglancer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw in a numpy volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446/446 [00:03<00:00, 115.75it/s]\n"
     ]
    }
   ],
   "source": [
    "def draw_numpy(section_structure_polygons, section_start, section_end):\n",
    "    volume = np.zeros((downsampled_aligned_shape[1], downsampled_aligned_shape[0], section_end - section_start), dtype=np.uint8)\n",
    "    for section in tqdm(range(section_start, section_end)):\n",
    "        if section in section_structure_polygons:\n",
    "            template = np.zeros((downsampled_aligned_shape[1], downsampled_aligned_shape[0]), dtype=np.uint8)\n",
    "            for structure in section_structure_polygons[section]:\n",
    "                polygons = section_structure_polygons[section][structure]\n",
    "                for polygon in polygons:\n",
    "                    #color = get_structure_number(structure)\n",
    "                    color = 10\n",
    "#                     cv2.polylines(template, [polygon.astype(np.int32)], True, color, 1)\n",
    "                    for point in polygon:\n",
    "                        cv2.circle(template, tuple(point.astype(np.int32)), 0, color, -1)\n",
    "\n",
    "            volume[:, :, section - section_start - 1] = template\n",
    "        \n",
    "    volume = np.swapaxes(volume, 0, 1)\n",
    "    return volume\n",
    "\n",
    "volume = draw_numpy(aligned_section_structure_polygons, 0, num_section)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1194, 875, 446)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volume.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_path = os.path.join(OUTPUT_DIR_PATH, f'{animal}_annotations_down{downsample_factor}.npy')\n",
    "with open(numpy_path, 'wb') as file:\n",
    "    np.save(file, volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:38637/v/5cfc4eac0b1f3bbcfa0020a247a8804d14871c7f/\n"
     ]
    }
   ],
   "source": [
    "import neuroglancer\n",
    "viewer = neuroglancer.Viewer()\n",
    "print(viewer)\n",
    "\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=scales), \n",
    "        voxel_offset=[0,0,0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers['all'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('MD589_CVAT_down32.pkl', 'rb') as file:\n",
    "    cvat_section_structure_polygons = pickle.load(file)\n",
    "volume = draw_numpy(cvat_section_structure_polygons, 0, num_section)\n",
    "\n",
    "all_volume_layer = neuroglancer.SegmentationLayer(\n",
    "    source = neuroglancer.LocalVolume(\n",
    "        data=volume, \n",
    "        dimensions=neuroglancer.CoordinateSpace(names=['x', 'y', 'z'], units='nm', scales=scales), \n",
    "        voxel_offset=[0,0,0]\n",
    "    ),\n",
    ")\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    s.layers['cvat'] = all_volume_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

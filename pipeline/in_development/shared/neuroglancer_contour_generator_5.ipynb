{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import neuroglancer\n",
    "import cv2\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting dklab@192.168.1.12:3306\n"
     ]
    }
   ],
   "source": [
    "HOME = os.path.expanduser(\"~\")\n",
    "PATH = os.path.join(HOME, 'programming/pipeline_utility')\n",
    "sys.path.append(PATH)\n",
    "from utilities.contour_utilities import get_contours_from_annotations, add_structure_to_neuroglancer, \\\n",
    "image_contour_generator\n",
    "neuroglancer.set_server_bind_address(bind_port='33645')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_filepath = os.path.join(PATH, 'neuroglancer/contours/json_cache', 'struct_to_color.json')\n",
    "with open(color_filepath, 'r') as json_file:\n",
    "    structure_to_color = json.load( json_file )\n",
    "    \n",
    "color_segments=[]\n",
    "for i in range(1,50):\n",
    "    color_segments.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD585'\n",
    "detector_id = 19\n",
    "# detector_id = 799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD589'\n",
    "detector_id = 19\n",
    "# detector_id = 799"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack = 'MD594'\n",
    "detector_id = 19\n",
    "# detector_id = 799"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neuroglancer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:33645/v/d5f4e50f3383a5571f048471c6062d331bec38b3/\n"
     ]
    }
   ],
   "source": [
    "viewer = neuroglancer.Viewer()\n",
    "# Sets 'Image' layer to be MD585 prep2 images from S3\n",
    "with viewer.txn() as s:\n",
    "    s.layers[stack] = neuroglancer.ImageLayer(source='precomputed://https://mousebrainatlas-datajoint-jp2k.s3.amazonaws.com/precomputed/'+stack+'_fullres')\n",
    "    s.layout = 'xy' # '3d'/'4panel'/'xy'\n",
    "print(viewer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuroglancer.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Aligned Volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "atlas_structures_wrt_wholebrainWithMargin_sections [87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371]\n",
      "key 87\n",
      "key 88\n",
      "key 89\n",
      "key 90\n",
      "key 91\n",
      "key 92\n"
     ]
    }
   ],
   "source": [
    "structure = 'SC'\n",
    "# color_codes{'blue:'1,'red',2,'yellow':3}\n",
    "str_contour, first_sec, last_sec = image_contour_generator( stack, detector_id, structure, use_local_alignment=True, image_prep=2, threshold=0.2)\n",
    "\n",
    "ng_structure_volume_normal = add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n",
    "                                                    color_radius=5, xy_ng_resolution_um=10, threshold=0.2, color=5, \\\n",
    "                                                    solid_volume=False, no_offset_big_volume=False, save_results=False, \\\n",
    "                                                    return_with_offsets=False, add_to_ng=True, human_annotation=False)\n",
    "\n",
    "#plt.imshow(ng_structure_volume_normal[20,:,:])\n",
    "ng_structure_volume_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for structure in all_structures_total:\n",
    "    str_contour, first_sec, last_sec = image_contour_generator( stack, detector_id, structure, use_local_alignment=True, image_prep=2, threshold=0.2)\n",
    "\n",
    "    add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n",
    "                                  color_radius=5, xy_ng_resolution_um=10, threshold=0.2, color=1, \\\n",
    "                                  solid_volume=False, no_offset_big_volume=False, save_results=False,\\\n",
    "                                  return_with_offsets=False, add_to_ng=True, human_annotation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CRAETE ENTIRE BRAIN VOLUME\n",
    "xy_ng_resolution_um = 5\n",
    "\n",
    "with open('struct_reverse_2.json', 'r') as json_file:\n",
    "    structure_to_color = json.load( json_file )\n",
    "\n",
    "    \n",
    "# MD585: x_um = 35617,           y_um = 26086\n",
    "# MD585: x_pixels_.46res = x_um*0.46,  y_pixels_.46res = y_um*0.46\n",
    "# MD585: x_pixels_newres = x_pixels_.46res*(0.46/newres), y_pixels_newres = y_pixels_.46res*(0.46/newres)\n",
    "# microns/resolution\n",
    "y_voxels = int( 26086*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "x_voxels = int( 35617*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "full_brain_volumes = np.zeros((268,y_voxels,x_voxels), dtype=np.uint8)\n",
    "\n",
    "for structure in all_structures_total:\n",
    "    str_contour, first_sec, last_sec = image_contour_generator( stack, detector_id, structure, use_local_alignment=True, image_prep=2, threshold=0.5)\n",
    "    \n",
    "    try:\n",
    "        color=structure_to_color[structure]\n",
    "    except:\n",
    "        color=2\n",
    "    \n",
    "    str_volume, xyz_offsets = add_structure_to_neuroglancer( viewer, str_contour, structure, stack, first_sec, last_sec, \\\n",
    "                                          color_radius=5, xy_ng_resolution_um=xy_ng_resolution_um, threshold=0.5, color=color, \\\n",
    "                                          solid_volume=False, no_offset_big_volume=True, save_results=False, return_with_offsets=True, \\\n",
    "                                          add_to_ng=False, human_annotation=False )\n",
    "    \n",
    "    z_len, y_len, x_len = np.shape(str_volume)\n",
    "    full_brain_volumes[0:z_len, 0:y_len, 0:x_len] += str_volume\n",
    "\n",
    "\n",
    "\n",
    "color_segments=[]\n",
    "for i in range(1,50):\n",
    "    color_segments.append(i)\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    #s.layers[ display_name ] = neuroglancer.SegmentationLayer(\n",
    "    s.layers[ \"full_brain\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data=full_brain_volumes, # Z,Y,X\n",
    "            voxel_size=[ xy_ng_resolution_um*1000, xy_ng_resolution_um*1000,20000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_array = np.ones((1,80,80), dtype=np.uint8)\n",
    "color_array[0,0:49,0]= np.array(color_segments)\n",
    "color_array[0,0,0:49]= np.array(color_segments)\n",
    "\n",
    "\n",
    "with viewer.txn() as s:\n",
    "    #s.layers[ display_name ] = neuroglancer.SegmentationLayer(\n",
    "    s.layers[ \"color_test\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data= color_array, # Z,Y,X\n",
    "            voxel_size=[ 50000, 50000,200000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Annotation Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! ls $ROOT_DIR/CSHL_labelings_v3/MD585/MD585_annotation_contours_05302018161849.hdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls $ROOT_DIR/CSHL_labelings_v3/$stack/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls $ROOT_DIR/CSHL_labelings_v3/MD585/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls $ROOT_DIR/CSHL_labelings_v3/MD589/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls $ROOT_DIR/CSHL_labelings_v3/MD594/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hand_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MD585\n",
    "if stack==\"MD585\":\n",
    "    hand_annotations = load_hdf_v2(ROOT_DIR+'/CSHL_labelings_v3/MD585/MD585_annotation_contours_05302018161849.hdf')\n",
    "if stack==\"MD589\":\n",
    "    hand_annotations = load_hdf_v2(ROOT_DIR+'/CSHL_labelings_v3/MD589/MD589_annotation_contours_05302018164231.hdf')\n",
    "if stack==\"MD594\":\n",
    "    hand_annotations = load_hdf_v2(ROOT_DIR+'/CSHL_labelings_v3/MD594/MD594_annotation_contours_05312018035134.hdf')\n",
    "    \n",
    "# Converts thw weird coordinate frame to a normal-ass prep2 raw frame\n",
    "hand_annotations = convert_annotation_v3_original_to_aligned_cropped_v2(\\\n",
    "                                        hand_annotations, stack=stack,\\\n",
    "                                        out_resolution='raw',\n",
    "                                        prep_id=2)\n",
    "\n",
    "\n",
    "num_annotations = len(hand_annotations)\n",
    "#hand_annotations.keys()\n",
    "\n",
    "\n",
    "MD585_ng_section_min = 83\n",
    "MD585_ng_section_max = 536\n",
    "# For sections before the 22nd section there is a weird offset that this compensates for\n",
    "MD585_abberation_correction = [9872, 4258] # UNUSED Currently\n",
    "\n",
    "def get_dense_coordinates( coor_list ):\n",
    "    dense_coor_list = []\n",
    "    # Shortest distance, x, y\n",
    "\n",
    "    #for x, y in coor_list:\n",
    "    for i in range(len(coor_list)-1):\n",
    "        x, y = coor_list[i]\n",
    "        x_next, y_next = coor_list[i+1]\n",
    "        \n",
    "        x_mid = (x+x_next)/2\n",
    "        y_mid = (y+y_next)/2\n",
    "        \n",
    "        \n",
    "        dense_coor_list.append([x,y])\n",
    "        dense_coor_list.append( [x_mid, y_mid] )\n",
    "        \n",
    "        if i==len(coor_list)-2:\n",
    "            dense_coor_list.append( [x_next, y_next] )\n",
    "            x, y = coor_list[0]\n",
    "            x_mid = (x+x_next)/2\n",
    "            y_mid = (y+y_next)/2\n",
    "            dense_coor_list.append( [x_mid, y_mid] )\n",
    "        \n",
    "    return dense_coor_list\n",
    "\n",
    "def get_contours_from_annotations( stack, target_str, densify=0 ):\n",
    "    str_contours_annotation = {}\n",
    "\n",
    "    for i in range(num_annotations):\n",
    "        structure = hand_annotations['name'][i]\n",
    "        side = hand_annotations['side'][i]\n",
    "        section = hand_annotations['section'][i]\n",
    "        \n",
    "        if side=='R' or side=='L':\n",
    "            structure = structure+'_'+side\n",
    "            \n",
    "        if structure==target_str:\n",
    "            vertices = hand_annotations['vertices'][i]\n",
    "            \n",
    "            for i in range(densify):\n",
    "                vertices = get_dense_coordinates( vertices )\n",
    "            \n",
    "            # Skip sections before the 22nd prep2 section for MD585 as there are clear errors\n",
    "            if stack=='MD585' and section < MD585_ng_section_min+22:\n",
    "                #vertices = vertices - np.array(MD585_abberation_correction)\n",
    "                continue\n",
    "\n",
    "            str_contours_annotation[section] = {}\n",
    "            str_contours_annotation[section][structure] = {}\n",
    "            str_contours_annotation[section][structure][1] = vertices\n",
    "\n",
    "    first_sec = np.min(str_contours_annotation.keys())\n",
    "    last_sec = np.max(str_contours_annotation.keys())\n",
    "    \n",
    "    return str_contours_annotation, first_sec, last_sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for target_str in all_structures_total[0:3]:\n",
    "for target_str in ['12N']:\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "\n",
    "    ng_structure_volume = add_structure_to_neuroglancer( viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                                                    color_radius=3, xy_ng_resolution_um=10, threshold=1, color=4, \\\n",
    "                                                    solid_volume=False, no_offset_big_volume=False, save_results=False, \\\n",
    "                                                    return_with_offsets=False, add_to_ng=True, human_annotation=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target_str in all_structures_total[0:3]:\n",
    "for target_str in ['7n_R']:\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "\n",
    "    ng_structure_volume = add_structure_to_neuroglancer( viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                                                    color_radius=3, xy_ng_resolution_um=10, threshold=1, color=4, \\\n",
    "                                                    solid_volume=False, no_offset_big_volume=False, save_results=False, \\\n",
    "                                                    return_with_offsets=False, add_to_ng=True, human_annotation=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for target_str in all_structures_total[0:3]:\n",
    "for target_str in ['7n_R']:\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "\n",
    "    ng_structure_volume = add_structure_to_neuroglancer( viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                                                    color_radius=3, xy_ng_resolution_um=10, threshold=1, color=4, \\\n",
    "                                                    solid_volume=False, no_offset_big_volume=True, save_results=False, \\\n",
    "                                                    return_with_offsets=False, add_to_ng=True, human_annotation=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REAL\n",
    "# 16384 x 12000 pixels raw\n",
    "# 35617 x 26086 um raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add all annotated brains to the viewer\n",
    "xy_ng_resolution_um = 5\n",
    "color_radius = 3\n",
    "\n",
    "# MD585: x_um = 35617,           y_um = 26086\n",
    "# MD585: x_pixels_.46res = x_um*0.46,  y_pixels_.46res = y_um*0.46\n",
    "# MD585: x_pixels_newres = x_pixels_.46res*(0.46/newres), y_pixels_newres = y_pixels_.46res*(0.46/newres)\n",
    "# microns/resolution\n",
    "y_voxels = 1+int( 26086*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "x_voxels = 1+int( 35617*0.46*(.46/xy_ng_resolution_um) + 0.5)\n",
    "full_brain_volume_annotated = np.zeros((268,y_voxels,x_voxels), dtype=np.uint8)\n",
    "\n",
    "for target_str in all_structures_total:\n",
    "# for target_str in['VCA_L','7n_R','7n_L']:\n",
    "    print(target_str)\n",
    "    str_contours_annotation, first_sec, last_sec = get_contours_from_annotations( stack, target_str, densify=4 )\n",
    "    \n",
    "    try:\n",
    "        color=structure_to_color[target_str]\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        color=4\n",
    "    \n",
    "    str_volume, xyz_str_offsets = add_structure_to_neuroglancer( \\\n",
    "                            viewer, str_contours_annotation, target_str, stack, first_sec, last_sec, \\\n",
    "                            color_radius=color_radius, xy_ng_resolution_um=xy_ng_resolution_um, threshold=1, color=color, \\\n",
    "                            solid_volume=False, no_offset_big_volume=True, save_results=True, \\\n",
    "                            return_with_offsets=True, add_to_ng=False, human_annotation=True  )\n",
    "    \n",
    "    z_len, y_len, x_len = np.shape(str_volume)\n",
    "#     full_brain_volume_annotated[0:z_len, 0:y_len, 0:x_len] = str_volume.copy()\n",
    "    for z in range( xyz_str_offsets[2], z_len ):\n",
    "        for y in range( xyz_str_offsets[1], y_len ):\n",
    "            for x in range( xyz_str_offsets[0], x_len ):\n",
    "                structure_val = str_volume[z, y, x]\n",
    "                if structure_val==0:\n",
    "                    continue\n",
    "                else:\n",
    "                    try:\n",
    "                        full_brain_volume_annotated[z, y, x] = structure_val\n",
    "                    except Exception as e:\n",
    "                        print(e)\n",
    "    \n",
    "with viewer.txn() as s:\n",
    "    s.layers[ stack+\"_Atlas\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data=full_brain_volume_annotated, # Z,Y,X\n",
    "            voxel_size=[ xy_ng_resolution_um*1000, xy_ng_resolution_um*1000,20000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with viewer.txn() as s:\n",
    "    s.layers[ stack+\"_Atlas\" ] = neuroglancer.SegmentationLayer(\n",
    "        source = neuroglancer.LocalVolume(\n",
    "            data=full_brain_volume_annotated, # Z,Y,X\n",
    "            voxel_size=[ xy_ng_resolution_um*1000, xy_ng_resolution_um*1000,20000], # X Y Z\n",
    "            voxel_offset = [ 0, 0, 0] # X Y Z\n",
    "        ),\n",
    "        segments = color_segments\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_annotation_fp = NEUROGLANCER_ROOT+stack+'/human_annotation/solid_volume_'+str(xy_ng_resolution_um)+'um/'\n",
    "full_annotation_fn = full_annotation_fp+'volume_colored.npy'\n",
    "print('Saving to :'+full_annotation_fp+full_annotation_fn)\n",
    "\n",
    "if not os.path.exists( full_annotation_fp ):\n",
    "    os.makedirs(full_annotation_fp)\n",
    "    \n",
    "np.save( full_annotation_fn, full_brain_volume_annotated )\n",
    "# radius <= 1 : wire\n",
    "#>radius <= 2 : thin\n",
    "#>radius <= 3.5 : ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir /home/alexn/Desktop/neuroglancer_binary_volumes/human_annotations_5um/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! aws s3 rm --recursive s3://test-bucket-sid/alex_neuroglancer_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! aws s3 cp --recursive $NEUROGLANCER_ROOT s3://test-bucket-sid/alex_neuroglancer_volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['ROOT_DIR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End Neuroglancer Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resets the viewer\n",
    "with viewer.txn() as s:\n",
    "    # Resets X/Y/Z plane orientation\n",
    "    s.navigation.pose.orientation = [0,0,0,1]\n",
    "    # Zooms out \n",
    "    s.navigation.zoomFactor = 10000\n",
    "    \n",
    "    # Resets 3D Viewer Orientation\n",
    "    s.perspectiveOrientation = [0,0,0,1]\n",
    "    # Zooms out\n",
    "    s.perspectiveZoom = 75000\n",
    "    \n",
    "    # Not necessary, just restates the voxel sizes of the image\n",
    "    s.navigation.pose.position.voxelSize = [460,460,20000]\n",
    "    # Sets Viewer's center location\n",
    "    s.navigation.pose.position.voxelCoordinates = [8192,6000,134]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wholeslice_to_brainstem = -from_padded_to_wholeslice, from_padded_to_brainstem\n",
    "\n",
    "#from_padded_to_wholeslice\n",
    "rostral_limit = 50\n",
    "caudal_limit = 1188\n",
    "dorsal_limit = 21\n",
    "ventral_limit = 738\n",
    "\n",
    "#from_padded_to_brainstem\n",
    "rostral_limit = 521\n",
    "caudal_limit = 1057\n",
    "dorsal_limit = 128\n",
    "ventral_limit = 465"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_volumes = '/home/alexn/Desktop/neuroglancer_binary_volumes/volumes_'+xy_ng_resolution_um+'um/'\n",
    "np.save( fp_volumes+structure+'_volume.npy',structure_volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "from skimage import io\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from scipy.ndimage.morphology import distance_transform_edt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/home/eddyod/programming/pipeline_utility'\n",
    "\n",
    "sys.path.append(PATH)\n",
    "from utilities.FileLocationManager import DATA_PATH, ROOT_DIR\n",
    "\n",
    "from utilities.SqlController import SqlController\n",
    "from utilities.atlas.imported_atlas_utilities import load_original_volume_all_known_structures_v3, get_centroid_3d, \\\n",
    "    load_alignment_results_v3, transform_points, average_location, \\\n",
    "    convert_to_original_name, name_unsided_to_color, paired_structures, \\\n",
    "    convert_to_left_name, convert_to_right_name, load_original_volume_v2, save_alignment_results_v3, \\\n",
    "    convert_transform_forms, transform_volume_v4, volume_to_polydata, singular_structures, \\\n",
    "    MESH_DIR, average_shape, convert_to_surround_name, mirror_volume_v2, save_original_volume, \\\n",
    "    save_mesh_stl, get_surround_volume_v2, transform_volume_v4, high_contrast_colors, \\\n",
    "    plot_centroid_means_and_covars_3d, all_known_structures_sided, load_data, \\\n",
    "    get_instance_mesh_filepath, images_to_volume_v2, find_contour_points, load_cropbox_v2, \\\n",
    "    load_mean_shape, \\\n",
    "    display_volume_sections, get_structure_mean_positions_filepath\n",
    "from utilities.atlas.atlas_aligner import Aligner\n",
    "from utilities.utilities_alignment import convert_resolution_string_to_um\n",
    "atlas_name = 'atlasV8'\n",
    "ATLAS_PATH = os.path.join(DATA_PATH, 'atlas_data', atlas_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_brain_name = 'MD589'\n",
    "sqlController = SqlController(fixed_brain_name)\n",
    "structures = sqlController.get_structures_list()\n",
    "structures.remove(\"R\")\n",
    "moving_brain_names = ['MD585', 'MD594']\n",
    "resolution = '10.0um'\n",
    "resolution_um = 10.0\n",
    "structure_centroids_all_brains_um_wrt_fixed = []\n",
    "fixed_brain_spec = {'name': fixed_brain_name, 'vol_type': 'annotationAsScore', 'resolution': resolution}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fixed_brain = load_original_volume_all_known_structures_v3(stack_spec=fixed_brain_spec, structures=structures, \n",
    "                                                           in_bbox_wrt='wholebrain')\n",
    "fixed_brain_structure_centroids = get_centroid_3d(fixed_brain)\n",
    "fixed_brain_structure_centroids_um = {s: c * resolution_um for s, c in fixed_brain_structure_centroids.items()}\n",
    "structure_centroids_all_brains_um_wrt_fixed.append(fixed_brain_structure_centroids_um)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute instance centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for brain_m in moving_brain_names:\n",
    "    moving_brain_spec = {'name': brain_m, 'vol_type': 'annotationAsScore', 'resolution': resolution}\n",
    "    print('Brain', moving_brain_spec)\n",
    "    moving_brain = load_original_volume_all_known_structures_v3(stack_spec=moving_brain_spec, \n",
    "                                                                structures=structures, in_bbox_wrt='wholebrain')\n",
    "    alignment_spec = dict(stack_m=moving_brain_spec, stack_f=fixed_brain_spec, warp_setting=109)\n",
    "    moving_brain_structure_centroids_input_resol = get_centroid_3d(moving_brain)\n",
    "    # Load registration.\n",
    "    # Alignment results fp: os.path.join(reg_root_dir, alignment_spec['stack_m']['name'], warp_basename, warp_basename + '_' + what + '.' + ext)\n",
    "    transform_parameters_moving_brain_to_fixed_brain = load_alignment_results_v3(alignment_spec=alignment_spec, what='parameters')\n",
    "    # Transform moving brains into alignment with the fixed brain.\n",
    "    transformed_moving_brain_structure_centroids_input_resol_wrt_fixed = \\\n",
    "    dict(list(zip(list(moving_brain_structure_centroids_input_resol.keys()),\n",
    "                  transform_points(pts=list(moving_brain_structure_centroids_input_resol.values()),\n",
    "                                   transform=transform_parameters_moving_brain_to_fixed_brain))))\n",
    "\n",
    "    transformed_moving_brain_structure_centroids_um_wrt_fixed = \\\n",
    "        {s: c * resolution_um for s, c in\n",
    "        list(transformed_moving_brain_structure_centroids_input_resol_wrt_fixed.items())}\n",
    "\n",
    "    structure_centroids_all_brains_um_wrt_fixed.append(transformed_moving_brain_structure_centroids_um_wrt_fixed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed = defaultdict(list)\n",
    "for sc in structure_centroids_all_brains_um_wrt_fixed:\n",
    "    for k, c in sc.items():\n",
    "        structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed[k].append(c)\n",
    "structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed.default_factory = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute standard centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_centroids_wrt_canonicalAtlasSpace_um, \\\n",
    "instance_centroids_wrt_canonicalAtlasSpace_um, \\\n",
    "canonical_center_wrt_fixed_um, \\\n",
    "canonical_normal, \\\n",
    "transform_matrix_to_canonicalAtlasSpace_um = \\\n",
    "average_location(structure_centroids_all_brains_um_grouped_by_structure_wrt_fixed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {name_s: np.array(name_unsided_to_color[convert_to_original_name(name_s)])/255.\n",
    "                                        for name_s in instance_centroids_wrt_canonicalAtlasSpace_um.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_centroid_means_and_covars_3d(instance_centroids=instance_centroids_wrt_canonicalAtlasSpace_um,\n",
    "                                 nominal_locations=nominal_centroids_wrt_canonicalAtlasSpace_um,\n",
    "                                 canonical_centroid=(0,0,0),\n",
    "                                  show_canonical_centroid=True,\n",
    "                                  canonical_normal=[0,0,1],\n",
    "                                 colors=colors,\n",
    "                                 xlim=[-3000, 3000],\n",
    "                                 ylim=[-3000, 3000],\n",
    "                                 zlim=[-3000, 3000],\n",
    "                                 xlabel='Rostral-caudal ($\\mu$m)',\n",
    "                                 ylabel='',\n",
    "                                 zlabel='Medial-lateral ($\\mu$m)',\n",
    "                                 title='Centroid means and covariances (3 brains)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(ATLAS_PATH, '1um_meanPositions.pkl')\n",
    "with open(filepath, 'wb') as f:\n",
    "    pickle.dump(nominal_centroids_wrt_canonicalAtlasSpace_um, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(ATLAS_PATH, 'canonicalCentroid_wrt_fixedWholebrain.txt')\n",
    "np.savetxt(filepath, canonical_center_wrt_fixed_um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_root_dir=os.path.join(ATLAS_PATH, 'mean_shapes', 'instance_registration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that all shapes have voxel resolution matching input resolution (10.0 micron).\n",
    "for structure in tqdm(structures):\n",
    "    # for structure in all_known_structures:\n",
    "    # Load instance volumes.\n",
    "    instance_volumes = []\n",
    "    instance_source = []\n",
    "\n",
    "    for brain_name in [fixed_brain_name] + moving_brain_names:\n",
    "        brain_spec = {'name': brain_name, 'vol_type': 'annotationAsScore', 'resolution': resolution}\n",
    "       \n",
    "        if '_L' in structure:\n",
    "            left_instance_vol, _ = load_original_volume_v2(stack_spec=brain_spec,\n",
    "                                                           structure=structure,\n",
    "                                                           return_origin_instead_of_bbox=True,\n",
    "                                                           crop_to_minimal=True)\n",
    "            instance_volumes.append(left_instance_vol[..., ::-1])  # if left, mirror\n",
    "            instance_source.append((brain_name, 'L'))\n",
    "        \n",
    "        else:\n",
    "            right_instance_vol, _ = load_original_volume_v2(stack_spec=brain_spec,\n",
    "                                                            structure=structure,\n",
    "                                                            return_origin_instead_of_bbox=True,\n",
    "                                                            crop_to_minimal=True)\n",
    "            instance_volumes.append(right_instance_vol)  # if right, do not mirror\n",
    "            instance_source.append((brain_name, 'R'))\n",
    "\n",
    "\n",
    "   # Use the first instance as registration target.\n",
    "    # Register every other instance to the first instance.\n",
    "    template_instance_volume = instance_volumes[0]\n",
    "    template_instance_centroid_wrt_templateOrigin = get_centroid_3d(template_instance_volume).astype(np.int16)\n",
    "    template_instance_wrt_templateCentroid = (template_instance_volume, - template_instance_centroid_wrt_templateOrigin)\n",
    "    aligned_moving_instance_wrt_templateCentroid_all_instances = []\n",
    "\n",
    "    for i in range(1, len(instance_volumes)):\n",
    "        # Compute transform.\n",
    "        moving_instance_volume = instance_volumes[i]\n",
    "        aligner = Aligner({0: template_instance_wrt_templateCentroid},\n",
    "                          {0: (moving_instance_volume, np.array((0,0,0)))},\n",
    "                          labelIndexMap_m2f={0:0},\n",
    "                         verbose=False)\n",
    "        aligner.set_centroid(centroid_m='structure_centroid', centroid_f='structure_centroid')\n",
    "        aligner.compute_gradient(smooth_first=True)\n",
    "        lr = 1.\n",
    "        ### max_iter_num was originally 100 and 1000\n",
    "        _, _ = aligner.optimize(tf_type='rigid',\n",
    "                                history_len=100,\n",
    "                                max_iter_num=2 if structure in ['SC', 'IC'] else 3,\n",
    "                                grad_computation_sample_number=None,\n",
    "                                full_lr=np.array([lr, lr, lr, 0.1, 0.1, 0.1]),\n",
    "                                terminate_thresh_trans=.01)\n",
    "\n",
    "\n",
    "\n",
    "        reg_root_dir=os.path.join(ATLAS_PATH, 'mean_shapes', 'instance_registration')\n",
    "        save_alignment_results_v3(aligner=aligner,\n",
    "                              select_best='max_value',\n",
    "                              alignment_spec=dict(warp_setting=108,\n",
    "                                                  stack_f=dict(name='%s_instance0' % structure, vol_type='annotationAsScore'),\n",
    "                                                  stack_m=dict(name='%s_instance%d' % (structure, i),\n",
    "                                                               vol_type='annotationAsScore')),\n",
    "                              reg_root_dir=reg_root_dir)\n",
    "\n",
    "        # Transform instances.\n",
    "        T = convert_transform_forms(aligner=aligner, out_form=(3, 4), select_best='max_value')\n",
    "        aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid = \\\n",
    "            transform_volume_v4(volume=(moving_instance_volume, (0, 0, 0)), transform=T,\n",
    "                                return_origin_instead_of_bbox=True)\n",
    "        aligned_moving_instance_wrt_templateCentroid = (\n",
    "        aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid)\n",
    "        aligned_moving_instance_wrt_templateCentroid_all_instances.append(aligned_moving_instance_wrt_templateCentroid)\n",
    "\n",
    "    # Generate meshes for each instance.\n",
    "    volume_origin_list = [template_instance_wrt_templateCentroid] + aligned_moving_instance_wrt_templateCentroid_all_instances\n",
    "    instance_mesh_wrt_templateCentroid_all_instances = [volume_to_polydata(volume, num_simplify_iter=3, smooth=True)\n",
    "        for volume, o in volume_origin_list]\n",
    "\n",
    "    # Save meshes.\n",
    "    #for i, mesh_data in enumerate(instance_mesh_wrt_templateCentroid_all_instances):\n",
    "    #    meshfile = '{}_{}_{}.stl'.format(resolution, structure, str(i))\n",
    "    #    meshpath = os.path.join(ATLAS_PATH, 'aligned_instance_meshes', meshfile)\n",
    "    #    #print('Save stl at {}'.format( meshpath))\n",
    "    #    save_mesh_stl(mesh_data, meshpath)\n",
    "\n",
    "    #filename = '{}_sources.pkl'.format(structure)\n",
    "    #filepath = os.path.join(ATLAS_PATH, 'instance_sources', filename)\n",
    "    #with open(filepath, 'wb') as f:\n",
    "    #    pickle.dump(instance_source, f)\n",
    "\n",
    "    # Compute average shape.\n",
    "\n",
    "    if structure == 'IC' or structure == 'SC':\n",
    "        # IC and SC boundaries are particularly jagged, so do a larger value smoothing.\n",
    "        sigma = 5.\n",
    "    else:\n",
    "        sigma = 2.\n",
    "\n",
    "\n",
    "    mean_shape_wrt_templateCentroid = \\\n",
    "        average_shape(volume_origin_list=volume_origin_list, force_symmetric=(structure in singular_structures),\n",
    "                      sigma=sigma,\n",
    "                      )\n",
    "\n",
    "    # Generate meshes for mean shape.\n",
    "    #mean_shape_isosurface_polydata_all_levels = {surface_level:\n",
    "    #                                                 volume_to_polydata(\n",
    "    #                                                     (mean_shape_wrt_templateCentroid[0] >= surface_level,\n",
    "    #                                                     mean_shape_wrt_templateCentroid[1]),\n",
    "    #                                                     num_simplify_iter=3, smooth=True)\n",
    "    #    for surface_level in np.arange(0.1, 1.1, .1)}\n",
    "\n",
    "    # Identify the surrouding area as additional structure.\n",
    "\n",
    "    wall_level = .5\n",
    "    surround_distance_um = 200.\n",
    "\n",
    "    # changed to v2 to v3 Jul/27/2020 renamed without the _vX\n",
    "    # volume, distance=5, wall_level=0, prob=False, return_origin_instead_of_bbox=True, padding=5\n",
    "    # def get_surround_volume(volume, origin, distance=5, wall_level=0, prob=False, return_origin_instead_of_bbox=True,\n",
    "    #                        padding=5):\n",
    "    surround_wrt_stdShapeCentroid = \\\n",
    "        get_surround_volume_v2(vol=mean_shape_wrt_templateCentroid[0],\n",
    "                               origin=mean_shape_wrt_templateCentroid[1],\n",
    "                               distance=surround_distance_um / resolution_um,\n",
    "                               wall_level=wall_level,\n",
    "                               prob=True,\n",
    "                               return_origin_instead_of_bbox=True,\n",
    "                               padding=5)\n",
    "\n",
    "    # Generate meshes for surrouding area.\n",
    "    #surround_isosurface_polydata_all_levels = {surface_level:\n",
    "    #         volume_to_polydata((surround_wrt_stdShapeCentroid[0] >= surface_level,\n",
    "    #                            surround_wrt_stdShapeCentroid[1]),\n",
    "    #                            num_simplify_iter=3, smooth=True)\n",
    "    #     for surface_level in np.arange(0.1, 1.1, .1)}\n",
    "\n",
    "    # Save mean shape.\n",
    "    filename = f'{structure}.npy'\n",
    "    filepath =  os.path.join(ATLAS_PATH, 'structure', filename)\n",
    "    np.save(filepath, np.ascontiguousarray(mean_shape_wrt_templateCentroid[0]))\n",
    "\n",
    "    filename = f'{structure}.txt'\n",
    "    filepath = os.path.join(ATLAS_PATH, 'origin', filename)\n",
    "    np.savetxt(filepath, mean_shape_wrt_templateCentroid[1])\n",
    "\n",
    "\n",
    "    #for level in np.arange(0.1, 1.1, .1):\n",
    "    #    filename = '{}_mesh_level_{}.stl'.format(structure, str(level))\n",
    "    #    filepath = os.path.join(ATLAS_PATH, 'mean_shapes', filename)\n",
    "    #    save_mesh_stl(mean_shape_isosurface_polydata_all_levels[level], filepath)\n",
    "\n",
    "    surround_name = convert_to_surround_name(structure, margin=str(int(surround_distance_um)) + 'um')\n",
    "    filename = '{}_volume.npy'.format(surround_name)\n",
    "    filepath = os.path.join(ATLAS_PATH, 'mean_shapes', filename)\n",
    "    np.save(filepath, np.ascontiguousarray(surround_wrt_stdShapeCentroid[0]))\n",
    "\n",
    "\n",
    "    filename = '{}_origin_wrt_meanShapeCentroid.txt'.format(surround_name)\n",
    "    filepath = os.path.join(ATLAS_PATH, 'mean_shapes', filename)\n",
    "    np.savetxt(filepath, surround_wrt_stdShapeCentroid[1])\n",
    "\n",
    "    #for level in np.arange(0.1, 1.1, .1):\n",
    "    #    filename = '{}_{}.stl'.format(surround_name, str(level))\n",
    "    #    filepath = os.path.join(ATLAS_PATH, 'mean_shapes', filename)\n",
    "    #    save_mesh_stl(surround_isosurface_polydata_all_levels[level], filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "template_instance_wrt_templateCentroid[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "# Compute transform.\n",
    "moving_instance_volume = instance_volumes[i]\n",
    "aligner = Aligner({0: template_instance_wrt_templateCentroid}, \n",
    "                  {0: (moving_instance_volume, np.array((0,0,0)))}, \n",
    "                  labelIndexMap_m2f={0:0})\n",
    "aligner.set_centroid(centroid_m='structure_centroid', centroid_f='structure_centroid')\n",
    "aligner.compute_gradient(smooth_first=True)\n",
    "lr = .1\n",
    "_, _ = aligner.optimize(tf_type='rigid', \n",
    "                     history_len=100, \n",
    "                    max_iter_num=100 if structure in ['SC', 'IC'] else 500,\n",
    "                     grad_computation_sample_number=None,\n",
    "                        full_lr=np.array([lr,lr,lr,0.1,0.1,0.1]),\n",
    "                       terminate_thresh_trans=.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_instance_volume.shape, moving_instance_volume.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aligner.Ts);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(aligner.scores);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# doesn't display much\n",
    "# Transform instances.\n",
    "\n",
    "T = convert_transform_forms(aligner=aligner, out_form=(3,4), select_best='max_value')\n",
    "\n",
    "aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid = \\\n",
    "transform_volume_v4((moving_instance_volume, (0,0,0)), transform=T,\n",
    "                    return_origin_instead_of_bbox=True)\n",
    "\n",
    "aligned_moving_instance_wrt_templateCentroid = (aligned_moving_instance_volume, aligned_moving_instance_origin_wrt_templateCentroid)        \n",
    "\n",
    "# Generate meshes for each instance.\n",
    "\n",
    "instance_mesh_wrt_templateCentroid_all_instances = [\n",
    "volume_to_polydata((v, o), num_simplify_iter=3, smooth=True)\n",
    "for v, o in \n",
    "[template_instance_wrt_templateCentroid] + [aligned_moving_instance_wrt_templateCentroid]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine standard shapes with standard centroid locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_resolution = '10.0um'\n",
    "atlas_resolution_um = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_spec = dict(name=atlas_name, vol_type='score', resolution=atlas_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shapes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.path.join(ATLAS_PATH, '1um_meanPositions.pkl')\n",
    "nominal_centroids = pickle.load( open(filepath, \"rb\" ) )\n",
    "nominal_centroids_10um = {s: c / atlas_resolution_um for s, c in nominal_centroids.items()}\n",
    "mean_shapes = {name_u: load_mean_shape(atlas_name=atlas_name, structure=name_u, resolution=atlas_resolution) \n",
    "                    for name_u in structures}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for structure in structures:\n",
    "\n",
    "    if '_L' in structure:\n",
    "        mean_shape = mirror_volume_v2(volume=mean_shapes[structure], \n",
    "                                      centroid_wrt_origin=-mean_shapes[structure][1],\n",
    "                                      new_centroid=nominal_centroids_10um[structure])\n",
    "    else:\n",
    "        mean_shape = (mean_shapes[structure][0], \n",
    "                        mean_shapes[structure][1] + nominal_centroids_10um[structure])\n",
    "        \n",
    "    volume = mean_shape[0]\n",
    "    origin = mean_shape[1]\n",
    "    print(structure, volume.shape, origin )\n",
    "    \n",
    "    # save origin, this is also the important one\n",
    "    filename = f'{structure}.txt'\n",
    "    filepath = os.path.join(ATLAS_PATH, 'origin', filename)\n",
    "    np.savetxt(filepath, origin)\n",
    "\n",
    "    # Save volume with stated level. This is the important one\n",
    "    filename = f'{structure}.npy'\n",
    "    filepath = os.path.join(ATLAS_PATH, 'structure', filename)\n",
    "    np.save(filepath, volume)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to vtk polydata for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#for name_s in all_known_structures_sided_including_surround_200um:\n",
    "for name_s in structures:\n",
    "    atlas_structure_wrt_canonicalAtlasSpace = \\\n",
    "    load_original_volume_v2(stack_spec=atlas_spec, structure=name_s, bbox_wrt='canonicalAtlasSpace')\n",
    "\n",
    "    for surface_level in np.arange(0.1, 1.1, .1):\n",
    "        mean_shape_isosurface_polydata_wrt_canonicalAtlasSpace = \\\n",
    "        volume_to_polydata(volume=(atlas_structure_wrt_canonicalAtlasSpace[0] >= surface_level, atlas_structure_wrt_canonicalAtlasSpace[1]), \n",
    "                     num_simplify_iter=3, smooth=True, \n",
    "                     return_vertex_face_list=False)\n",
    "        path = '/home/eddyod/tmp/meshes'\n",
    "        if surface_level == 0.2:\n",
    "            filepath = os.path.join(path, '{}_{}.stl'.format(name_s, surface_level))\n",
    "            save_mesh_stl(mean_shape_isosurface_polydata_wrt_canonicalAtlasSpace, filepath)\n",
    "        #save_data(mean_shape_isosurface_polydata_wrt_canonicalAtlasSpace, \n",
    "        #          DataManager.get_mesh_filepath_v2(atlas_spec, structure=name_s, level=surface_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_shape_level05isosurface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "{name_s: load_data(DataManager.get_mesh_filepath_v2(atlas_spec, structure=name_s, level=0.5))\n",
    "for name_s in all_known_structures_sided}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch_vtk([actor_mesh(v, wireframe=False, opacity=.5, color=name_unsided_to_color_float[convert_to_original_name(s)]) \n",
    "#            for s, v in mean_shape_level05isosurface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "#          + [actor_sphere([0,0,0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use MD589's shell, until we find a way to average the outlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_fixed = 'MD589'\n",
    "MASKS = '/net/birdstore/Active_Atlas_Data/data_root/brains_info/masks/{}/aligned'.format(stack_fixed)\n",
    "margin_um = 200\n",
    "in_resolution_um = 0.46 * 32\n",
    "margin_tb = margin_um / XY_PIXEL_DISTANCE_TB\n",
    "for stack in ['MD589']:\n",
    "    #sqlController = SqlController(stack)\n",
    "#     contours_valid_by_z = {}\n",
    "    contour_prob_maps_by_sec = {} \n",
    "    sections = sorted(os.listdir(MASKS))\n",
    "    i = 1\n",
    "    for sec in sections[0:10]:\n",
    "        maskfile = os.path.join(MASKS, sec)\n",
    "        m = io.imread(maskfile)\n",
    "        contours = find_contour_points(m, sample_every=1)[1]\n",
    "        contours_valid = [cnt[(cnt[:,0] >= 1) & (cnt[:,1] >= 1)] for cnt in contours]\n",
    "#         z = np.mean(DataManager.convert_section_to_z(stack, sec, downsample=32, z_begin=0))\n",
    "#         contours_valid_by_z[z] = contours_valid[0]\n",
    "        m2 = np.zeros_like(m, np.bool)\n",
    "        for cnt in contours_valid:\n",
    "            m2[cnt[:,1], cnt[:,0]] = 1\n",
    "        distance_to_contour = distance_transform_edt(~m2)\n",
    "        contour_prob_map = np.exp(-distance_to_contour**2/(2*margin_tb)**2)\n",
    "        contour_prob_map[contour_prob_map < 1e-2] = 0\n",
    "        contour_prob_maps_by_sec[i] = contour_prob_map\n",
    "        i += 1\n",
    "        \n",
    "outline_prob_volume_atlasResol, outline_prob_volume_origin_wrt_wholebrainXYcropped_atlasResol = \\\n",
    "images_to_volume_v2(images=contour_prob_maps_by_sec, spacing_um=20, \n",
    "                    in_resol_um = in_resolution_um,\n",
    "                    out_resol_um = atlas_resolution_um)                                                                    \n",
    "#outline_prob_volume_bbox (xm,xm,ym,ym) relative to cropped, (zm,zm) relative to uncropped.\n",
    "# crop_box = metadata_cache['cropbox']['MD589']\n",
    "alignedBrainstemCrop_cropbox_down32 = load_cropbox_v2(stack=stack_fixed, prep_id='alignedBrainstemCrop')\n",
    "alignedBrainstemCrop_cropbox_atlasResol = alignedBrainstemCrop_cropbox_down32 * in_resolution_um / atlas_resolution_um\n",
    "outline_prob_volume_origin_rel2fixedwholebrain_atlasResol = outline_prob_volume_origin_wrt_wholebrainXYcropped_atlasResol + (alignedBrainstemCrop_cropbox_atlasResol[0], alignedBrainstemCrop_cropbox_atlasResol[2], 0)\n",
    "#display_volume_sections(outline_prob_volume, direction='z', ncols=5, cmap=plt.cm.gray, start_level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outline_prob_volume_origin_rel2canon_atlasResol = outline_prob_volume_origin_rel2fixedwholebrain_atlasResol - \\\n",
    "canonical_center_wrt_fixed_um/convert_resolution_string_to_um(resolution='10.0um')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_vol_origin_dict_rel2canon = {'shell': (outline_prob_volume_atlasResol, outline_prob_volume_origin_rel2canon_atlasResol)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Side task: compute the volumes of structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atlas_resolution = '10.0um'\n",
    "atlas_resolution_um = 10.0\n",
    "atlas_spec = dict(name='atlasV7', vol_type='score', resolution=atlas_resolution)\n",
    "volumes = load_original_volume_all_known_structures_v3(atlas_spec, \n",
    "                           structures=all_known_structures_sided, in_bbox_wrt='canonicalAtlasSpace')\n",
    "\n",
    "volumes_mm3 = defaultdict(dict)\n",
    "structures = ['SC', 'IC']\n",
    "for name_u in structures:\n",
    "    for level in np.arange(0, 1.1, .1):\n",
    "        volumes_mm3[name_u][level] = np.count_nonzero(volumes[convert_to_left_name(name_u)][0] > level) * 10.**3 / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(volumes_mm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_shape_level05surface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "DataManager.load_meshes_v2(atlas_spec, levels=.5, include_surround=True, \n",
    "                           structures=all_known_structures_sided)\n",
    "#                            structures=all_known_structures_sided + all_known_structures_sided_with_surround_200um)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_vtk([actor_mesh(p, wireframe=True) \n",
    "           for s, p in standard_shape_level05surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "            + [actor_sphere((0,0,0), radius=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show multiple iso-surfaces\n",
    "\n",
    "standard_shape_level010surface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "DataManager.load_meshes_v2(atlas_spec, levels=.1, include_surround=True, \n",
    "                           structures=all_known_structures_sided)\n",
    "#                            structures=all_known_structures_sided + all_known_structures_sided_with_surround_200um)\n",
    "\n",
    "standard_shape_level090surface_polydata_wrt_canonicalAtlasSpace_all_structures = \\\n",
    "DataManager.load_meshes_v2(atlas_spec, levels=.9, include_surround=True, \n",
    "                           structures=all_known_structures_sided)\n",
    "#                            structures=all_known_structures_sided + all_known_structures_sided_with_surround_200um)\n",
    "\n",
    "launch_vtk([actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.2) \n",
    "           for s, p in standard_shape_level010surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "           + [actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.1) \n",
    "           for s, p in standard_shape_level090surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "            + [actor_sphere((0,0,0), radius=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load shell\n",
    "\n",
    "stack_fixed = 'MD589'\n",
    "shell_polydata_rel2fixedWholebrain = DataManager.load_mesh_v2(brain_spec={'name':stack_fixed, \n",
    "                                                                    'vol_type':'annotationAsScore',\n",
    "                                                                   'resolution':'10.0um'}, \n",
    "                                                        structure='shell')\n",
    "\n",
    "shell_polydata_rel2canonicalAtlasSpace = move_polydata(shell_polydata_rel2fixedWholebrain,\n",
    "                                                       -canonical_center_wrt_fixed_um / convert_resolution_string_to_um(resolution='10.0um'))\n",
    "\n",
    "shell_actor_rel2canon = actor_mesh(shell_polydata_rel2fixedWholebrain, (1,1,1), opacity=.15, \n",
    "                              wireframe=False, origin=-canonical_center_wrt_fixed_um / convert_resolution_string_to_um(resolution='10.0um'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(shell_polydata_rel2canonicalAtlasSpace, \n",
    "          DataManager.get_mesh_filepath_v2(atlas_spec, structure='shell', level=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_vtk([actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.2) \n",
    "           for s, p in standard_shape_level010surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "           + [actor_mesh(p, wireframe=False, color=name_unsided_to_color_float[convert_to_unsided_label(s)], opacity=.1) \n",
    "           for s, p in standard_shape_level090surface_polydata_wrt_canonicalAtlasSpace_all_structures.iteritems()] \\\n",
    "            + [actor_sphere((0,0,0), radius=1)]\\\n",
    "#           +[shell_actor_rel2canon] \\\n",
    "           +[actor_mesh(shell_polydata_rel2canonicalAtlasSpace, (1,1,1), opacity=.15, \n",
    "                              wireframe=False)]\n",
    "#           +[actor_volume(shell_vol_origin_dict_rel2canon['shell'][0].astype(np.float32), \n",
    "#                          what='probability', origin=shell_vol_origin_dict_rel2canon['shell'][1])]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atlas_volume, structure_to_label, label_to_structure = \\\n",
    "# DataManager.load_original_volume_all_known_structures(stack=atlas_name, sided=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol, origin_rel2canon = structure_vol_origin_dicts_rel2canon['7N_L']\n",
    "\n",
    "one_structure_volume_actor_rel2canon = actor_volume(vol.astype(np.float32), what='score', \n",
    "                                              origin=origin_rel2canon,\n",
    "                                                    auxdata=0.8*(vol>0.1).astype(np.float32),\n",
    "                                              c=np.array(name_unsided_to_color['7N'])/255.)\n",
    "#                                             c=np.array((1,0,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_vtk([] \\\n",
    "    + structure_mesh_actors_rel2canon \\\n",
    "#     + [one_structure_volume_actor_rel2canon] \\\n",
    "#     + [shell_volume_actor_rel2canon] \\\n",
    "#     + structure_mesh_surround_actors_rel2canon \\\n",
    "    + [shell_actor_rel2canon] \\\n",
    "    + [actor_sphere((0,0,0), radius=1)], \n",
    "           init_angle='sagittal', \n",
    "    background_color=(1,1,1),\n",
    "depth_peeling=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

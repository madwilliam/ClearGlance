{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import io\n",
    "from os.path import expanduser\n",
    "from tqdm import tqdm\n",
    "HOME = expanduser(\"~\")\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask, hidden_layer, num_classes)\n",
    "    return model\n",
    "\n",
    "modelpath = os.path.join(HOME, '/net/birdstore/Active_Atlas_Data/data_root/brains_info/masks/mask.model.pth')\n",
    "loaded_model = get_model_instance_segmentation(num_classes=2)\n",
    "if os.path.exists(modelpath):\n",
    "    loaded_model.load_state_dict(torch.load(modelpath,map_location=torch.device('cpu')))\n",
    "else:\n",
    "    print('no model to load')\n",
    "transform = torchvision.transforms.ToTensor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dims(a):\n",
    "    if a.shape[0] > 0:\n",
    "        a1 = a[0,:,:]\n",
    "        a2 = a[1,:,:]\n",
    "        a3 = np.add(a1,a2)\n",
    "    else:\n",
    "        a3 = np.zeros([a.shape[1], a.shape[2]]) + 255\n",
    "    return a3\n",
    "\n",
    "def greenify_mask(image):\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    g = np.zeros_like(image).astype(np.uint8)\n",
    "    b = np.zeros_like(image).astype(np.uint8)\n",
    "    r[image == 1], g[image == 1], b[image == 1] = [255,255,255]\n",
    "    coloured_mask = np.stack([r, g, b], axis=2)\n",
    "    return coloured_mask\n",
    "\n",
    "def merge_mask(image, mask):\n",
    "    b = mask\n",
    "    g = image\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    merged = np.stack([r, g, b], axis=2)\n",
    "    return merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DIR = os.path.join(HOME, 'programming', 'dk39')\n",
    "DIR = '/net/birdstore/Active_Atlas_Data/data_root/pipeline_data/DK63/preps'\n",
    "INPUT = os.path.join(DIR, 'CH1/normalized')\n",
    "MASKS = os.path.join(DIR, 'thumbnail_masked')\n",
    "GREENS = os.path.join(DIR, 'thumbnail_green')\n",
    "TESTS = os.path.join(DIR, 'thumbnail_test')\n",
    "os.makedirs(TESTS, exist_ok=True)\n",
    "files = sorted(os.listdir(INPUT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bads = [116,119,127,132,140]\n",
    "bads = [str(b).zfill(3) + '.tif' for b in bads]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "loaded_model.eval()\n",
    "file = '011.tif'\n",
    "infile = os.path.join(INPUT, file)\n",
    "outpath = os.path.join(MASKS, file)\n",
    "test_path = os.path.join(TESTS, file)\n",
    "img = Image.open(infile)\n",
    "input = transform(img)\n",
    "input = input.unsqueeze(0)\n",
    "with torch.no_grad():\n",
    "    pred = loaded_model(input)\n",
    "pred_score = list(pred[0]['scores'].detach().numpy())\n",
    "masks = [(pred[0]['masks']>0.5).squeeze().detach().cpu().numpy()]\n",
    "mask = masks[0]\n",
    "dims = mask.ndim\n",
    "if dims > 2:\n",
    "    mask = combine_dims(mask)\n",
    "\n",
    "#del img\n",
    "#raw_img = cv2.imread(infile, -1)\n",
    "raw_img = np.array(img)\n",
    "mask = mask.astype(np.uint8)\n",
    "mask[mask>0] = 255\n",
    "merged_img = merge_mask(raw_img, mask)\n",
    "#cv2.imwrite(test_path, merged_img)    \n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(merged_img, cmap=\"gray\")\n",
    "plt.title('merged:{}'.format(file), fontsize=30)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "infile = os.path.join(GREENS, '024.tif')\n",
    "img = cv2.imread(infile, -1)\n",
    "mask = img[:,:,2]\n",
    "mask[mask>0] = 255\n",
    "print(mask.dtype, mask.shape, np.unique(mask))\n",
    "\n",
    "fig=plt.figure(figsize=(26,18), dpi= 100, facecolor='w', edgecolor='k')\n",
    "plt.imshow(r, cmap=\"gray\")\n",
    "plt.title('r:{}'.format(file), fontsize=30)\n",
    "plt.tick_params(axis='x', labelsize=30)\n",
    "plt.tick_params(axis='y', labelsize=30)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
